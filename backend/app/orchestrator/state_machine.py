"""Pipeline orchestrator chaining the agents with totals validation."""
from __future__ import annotations

import logging
from dataclasses import dataclass
from typing import Any, Mapping, Optional

from app.agents.accountant import AccountantAgent
from app.agents.auditor import AuditorAgent
from app.agents.classifier import ClassifierAgent
from app.agents.cross_validator import CrossValidatorAgent
from app.agents.extractor import ExtractorAgent
from app.agents.intelligence import IntelligenceAgent
from app.core.totals import ensure_document_totals, to_float, totals_as_dict
from app.schemas import (
    AccountingOutput,
    AuditReport,
    ClassificationResult,
    CrossValidationReport,
    Document,
    DocumentIn,
    InsightReport,
)
from app.services.diagnostic_logger import log_totals_event, update_post_validation_benchmark
from app.services.orchestrator.budget import TokenBudgetManager
from app.services.orchestrator.prompt_optimizer import PromptOptimizer

logger = logging.getLogger(__name__)


@dataclass(slots=True)
class PipelineRunResult:
    """Container holding the artifacts generated by a pipeline execution."""

    document: Document
    audit: AuditReport
    classification: ClassificationResult
    accounting: AccountingOutput
    cross_validation: CrossValidationReport
    insight: InsightReport


class PipelineOrchestrator:
    def __init__(
        self,
        *,
        budget_manager: Optional[TokenBudgetManager] = None,
        prompt_optimizer: Optional[PromptOptimizer] = None,
    ) -> None:
        self.budget_manager = budget_manager
        self.prompt_optimizer = prompt_optimizer or PromptOptimizer()
        self.extractor = ExtractorAgent()
        self.auditor = AuditorAgent()
        self.classifier = ClassifierAgent()
        self.accountant = AccountantAgent()
        self.cross_validator = CrossValidatorAgent()
        self.intelligence = IntelligenceAgent(prompt_optimizer=self.prompt_optimizer)

    def _consume_stage(self, agent: str, step: str, metadata: Mapping[str, Any] | None) -> None:
        if not self.budget_manager:
            return
        self.budget_manager.consume_for_stage(agent, step, metadata)

    def _load_corrections(self, metadata: Mapping[str, Any] | None) -> dict[str, str]:
        if not isinstance(metadata, Mapping):
            return {}

        raw_job_id = metadata.get("job_id") or metadata.get("jobId")
        if not isinstance(raw_job_id, str):
            return {}

        try:
            job_id = uuid.UUID(str(raw_job_id))
        except (ValueError, TypeError):
            logger.debug("Ignoring invalid job_id metadata for corrections: %s", raw_job_id)
            return {}

        with get_session() as session:
            corrections = list_corrections_map(session, job_id)

        materialized = {document: operation.value for document, operation in corrections.items()}
        if materialized:
            logger.info(
                {
                    "evt": "orchestrate_corrections_loaded",
                    "job_id": str(job_id),
                    "count": len(materialized),
                }
            )
        return materialized

    def _totals_needs_attention(self, totals: Any) -> bool:
        if totals is None:
            return True
        totals_dict = totals_as_dict(totals)
        return any(to_float(value) == 0.0 for value in totals_dict.values())

    def run(self, document_in: DocumentIn) -> PipelineRunResult:
        metadata = document_in.metadata if hasattr(document_in, "metadata") else None
        self._consume_stage("ocr", "ingest", metadata)
        document = self.extractor.run(document_in)
        document = ensure_document_totals(document)  # type: ignore[assignment]
        logger.info(
            {
                "evt": "orchestrate_step",
                "step": "extract",
                "doc_id": document_in.document_id,
                "items": len(getattr(document, "items", [])),
                "totals": totals_as_dict(document.totals),
            }
        )

        self._consume_stage("auditor", "analysis", metadata)
        audit = self.auditor.run(document)
        corrections = self._load_corrections(document_in.metadata if hasattr(document_in, "metadata") else None)
        self._consume_stage("classifier", "classification", metadata)
        classification = self.classifier.run(audit, corrections=corrections)
        self._consume_stage("accountant", "reconciliation", metadata)
        accounting = self.accountant.run(classification)
        logger.info(
            {
                "evt": "orchestrate_step",
                "step": "account",
                "doc_id": document_in.document_id,
                "totals": totals_as_dict(accounting.totals),
            }
        )

        if self._totals_needs_attention(accounting.totals):
            logger.warning(
                "Null totals detected for document %s. Triggering AccountantAgent recompute.",
                document_in.document_id,
            )
            if accounting.document is not None:
                repaired_document = AccountantAgent.recompute_totals(
                    accounting.document, document_id=document_in.document_id
                )
                if hasattr(repaired_document, "totals"):
                    accounting.document = repaired_document
                    accounting.totals = getattr(repaired_document, "totals", accounting.totals)
                    log_totals_event(
                        agent="orchestrator",
                        stage="post_accountant_validation",
                        document_id=document_in.document_id,
                        totals=accounting.totals,
                        status="recomputed",
                    )

        update_post_validation_benchmark(
            document_id=document_in.document_id,
            totals=accounting.totals,
            notes="post_accountant_validation",
        )
        logger.info(
            {
                "evt": "orchestrate_step",
                "step": "post_validation",
                "doc_id": document_in.document_id,
                "totals": totals_as_dict(accounting.totals),
            }
        )

        self._consume_stage("crossValidator", "consistency", metadata)
        cross_validation = self.cross_validator.run(document, audit, classification, accounting)
        self._consume_stage("intelligence", "insight", metadata)
        insights = self.intelligence.run(accounting, budget_manager=self.budget_manager)
        return PipelineRunResult(
            document=document,
            audit=audit,
            classification=classification,
            accounting=accounting,
            cross_validation=cross_validation,
            insight=insights,
        )


def build_pipeline() -> PipelineOrchestrator:
    return PipelineOrchestrator()
